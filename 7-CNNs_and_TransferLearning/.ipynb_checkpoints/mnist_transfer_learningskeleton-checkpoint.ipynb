{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "\n",
    "# Code to visualize the execution graph in the jupyter notebook\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image,title=None):\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image.astype(np.uint8),interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "def getActivations(layer,stimuli):\n",
    "    units = sess.run(layer,feed_dict={X:np.reshape(stimuli,[1,784],order='F')})\n",
    "    plotNNFilter(units)\n",
    "\n",
    "# visualize convolution activations\n",
    "def plotNNFilter(units):\n",
    "    filters = units.shape[3]\n",
    "    #print (filters)\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "    \n",
    "\n",
    "# visualize convolution kernels\n",
    "def plotConvLayerWeights(conv_layer_name, sess):\n",
    "    kernel = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, conv_layer_name)[0]\n",
    "    #print (kernel)\n",
    "    weights = sess.run(kernel)\n",
    "    #print (weights)\n",
    "    print(kernel.shape)\n",
    "    \n",
    "    n_filters = int(kernel.shape[3])\n",
    "    n_base_layers = int(kernel.shape[2])\n",
    "    plt.figure(figsize=(20,20))\n",
    "    for j in range(n_base_layers):\n",
    "        for i in range(n_filters):\n",
    "            plt.subplot(n_base_layers, n_filters, j * n_filters + i + 1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.imshow(weights[:,:,j,i].reshape(kernel.shape[0],kernel.shape[1]), cmap='gray', interpolation='nearest')\n",
    "            plt.title(str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 1459 and 023678 from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-3159045fbfa1>:9: Dataset.from_tensor_slices (from tensorflow.contrib.data.python.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.from_tensor_slices()`.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAELCAYAAADZdzObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f259a765fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAELCAYAAADZdzObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAB71JREFUeJzt3T+IlNsdx+Hz6m2CyS2CS8BmLUwU\nE0gsVEixgpUWwjaiRESQ4J+I2gYXxNsqWLnsYicpkkYCi9nCRhBhGy0s4sIFQYUgRiWYGJFs9E1x\nTUjuvXPejTs7s+73ecr9OTPnzoWPx33PvNO0bVuAXGuGvQBguEQAwokAhBMBCCcCEE4EIJwIQDgR\noKppmu83TfP7pmn+3jTN46ZpfjHsNdFfnw17Aax4k6WUf5RSflBK+Vkp5Q9N09xv2/aPw10W/dI4\nMUgvTdOsK6X8pZTyk7Ztv/zws9+UUv7Utu2vh7o4+sY/B6j5USnln/8OwAf3Syk/HtJ6WAYiQM13\nSyl//drPXpVSvjeEtbBMRICa16WUz7/2s89LKX8bwlpYJiJAzZellM+apvnhf/3sp6UUvxRcRfxi\nkKqmaX5XSmlLKb8sX10dmC2l/NzVgdXDToAuvyqlfKeU8udSym9LKScFYHWxE4BwdgIQTgQgnAhA\nOBGAcEP5AFHTNH4bCcusbdtmMX/OTgDCiQCEEwEIJwIQTgQgnAhAOBGAcCIA4UQAwokAhBMBCCcC\nEE4EIJwIQDgRgHAiAOFEAMKJAIQTAQgnAhBOBCCcCEA4EYBwIgDhRADCiQCEEwEIJwIQTgQgnAhA\nuKF8NTmDt27duur80qVL1fnx48er83v37lXn+/fv7zl7/Phx9bEsLzsBCCcCEE4EIJwIQDgRgHAi\nAOFEAMI1bdsO/kWbZvAvGm7Tpk3V+fz8/JKef82a+t8nZ86c6TmbnJxc0mvz7dq2bRbz5+wEIJwI\nQDgRgHAiAOFEAMKJAIQTAQjnfgKryMjISM/ZtWvXBrgSPiV2AhBOBCCcCEA4EYBwIgDhRADCuUT4\nCal9HLeUUsbHx3vOduzY0e/l/F/GxsZ6zro+hnz//v3q/Pbt2x+1Jr5iJwDhRADCiQCEEwEIJwIQ\nTgQgnAhAOLcc/4S8e/euOn///v2AVvJNXdf6l7K2rq8uP3DgQHXe9bXpq5VbjgOLIgIQTgQgnAhA\nOBGAcCIA4UQAwjknsILMzs5W53v37q3Oh3lO4OXLl9X569eve85GR0f7vZz/sXbt2mV9/pXKOQFg\nUUQAwokAhBMBCCcCEE4EIJwIQDjfOzBAu3btqs43b95cnXedA1jOcwLT09PV+c2bN6vzV69e9Zzt\n3r27+tiJiYnqvMvJkyd7zqamppb03KuBnQCEEwEIJwIQTgQgnAhAOBGAcCIA4dxPoI82btxYnc/N\nzVXn69evr86Xcm//rnv3X79+vTr/4osvqvM3b95U5zVd9xPoet9GRkaq87dv3/acnT9/vvrYK1eu\nVOcLCwvV+TC5nwCwKCIA4UQAwokAhBMBCCcCEM4lwj7atGlTdT4/P7+k5++6RHjr1q2es4MHD1Yf\n++LFi49a0yCcPn26Or98+XJ1Xnvfuj5+vWXLlur84cOH1fkwuUQILIoIQDgRgHAiAOFEAMKJAIQT\nAQjnluOfkLt371bnR48e7TlbyecAuszMzFTnhw4dqs63b9/ez+WsOnYCEE4EIJwIQDgRgHAiAOFE\nAMKJAIRzTmCAuu4H0GXnzp19WsmnpWnqH4vvel+X8r5fuHChOj98+PBHP/dKYScA4UQAwokAhBMB\nCCcCEE4EIJwIQDjnBProxIkT1XnXPe75dvv27avOt23bVp3X3veu/ydd5wRWAzsBCCcCEE4EIJwI\nQDgRgHAiAOFEAMI5J9BHXdezk42MjPScbd26tfrYc+fO9Xs5//H8+fPqfGFhYdlee6WwE4BwIgDh\nRADCiQCEEwEIJwIQziVCBmJiYqLn7NSpU8v62o8ePeo5O3LkSPWxT5486fNqVh47AQgnAhBOBCCc\nCEA4EYBwIgDhRADCOSdAX8zOzlbnmzdvHtBKvunBgwc9Z3fu3BngSlYmOwEIJwIQTgQgnAhAOBGA\ncCIA4UQAwjkn0EdN01Tna9Ysrbl79+796MdevXq1Ot+wYcNHP3cp3f9tw/xadreCr7MTgHAiAOFE\nAMKJAIQTAQgnAhBOBCCccwJ9NDU1VZ1fvHhxSc9/48aN6nwp1+KX+zr+cj7/9PT0sj13AjsBCCcC\nEE4EIJwIQDgRgHAiAOGatm0H/6JNM/gXHYDR0dHqfG5urjofGRmpzlfyx3W71vbs2bOes/n5+epj\njx07Vp0/ffq0On/z5k11vlq1bVv/bPsHdgIQTgQgnAhAOBGAcCIA4UQAwokAhHNOYIDGxsaq8/Hx\n8er87Nmz1flKPidw5syZnrPJycl+L4finACwSCIA4UQAwokAhBMBCCcCEE4EIJxzAp+QPXv2VOe1\nz913fT33zMxMdd711eZdX8v+4MGDnrMnT55UH8vHcU4AWBQRgHAiAOFEAMKJAIQTAQgnAhDOOQFY\npZwTABZFBCCcCEA4EYBwIgDhRADCiQCEEwEIJwIQTgQgnAhAOBGAcCIA4UQAwokAhBMBCCcCEE4E\nIJwIQDgRgHAiAOFEAMKJAIQTAQgnAhBOBCCcCEA4EYBwIgDhRADCDeWryYGVw04AwokAhBMBCCcC\nEE4EIJwIQDgRgHAiAOFEAMKJAIQTAQgnAhBOBCCcCEA4EYBwIgDhRADCiQCEEwEIJwIQTgQgnAhA\nOBGAcCIA4UQAwokAhPsX8l1n9PoS/nUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25b733d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_data():\n",
    "    global  dataset_1459_train, \\\n",
    "            dataset_023678_train, \\\n",
    "            X_1459_train, \\\n",
    "            y_1459_train, \\\n",
    "            X_1459_test, \\\n",
    "            y_1459_test, \\\n",
    "            X_023678_test, \\\n",
    "            y_023678_test, \\\n",
    "            X_023678_train, \\\n",
    "            y_023678_train\n",
    "    mask_1459_train = np.logical_or.reduce([mnist.train.labels == v for v in [1,4,5,9]])\n",
    "    mask_1459_test  = np.logical_or.reduce([mnist.test.labels  == v for v in [1,4,5,9]])\n",
    "    #print(mask_1459_test)\n",
    "    X_1459_train = np.compress(np.array(mask_1459_train), mnist.train.images, axis=0)\n",
    "    #print(X_1459_train)\n",
    "    _, y_1459_train = np.unique(mnist.train.labels[mask_1459_train], return_inverse=True) # 1,4,5,9 to 0,1,2,3\n",
    "    dataset_1459_train = tf.contrib.data.Dataset.from_tensor_slices((X_1459_train,y_1459_train))\n",
    "    \n",
    "    X_1459_test = np.compress(np.array(mask_1459_test), mnist.test.images, axis=0)\n",
    "    _, y_1459_test = np.unique(mnist.test.labels[mask_1459_test], return_inverse=True)\n",
    "    \n",
    "    mask_023678_train = np.logical_or.reduce([mnist.train.labels == v for v in [0,2,3,6,7,8]])\n",
    "    mask_023678_test  = np.logical_or.reduce([mnist.test.labels  == v for v in [0,2,3,6,7,8]])\n",
    "    X_023678_train = np.compress(np.array(mask_023678_train), mnist.train.images, axis=0)\n",
    "    _, y_023678_train = np.unique(mnist.train.labels[mask_023678_train], return_inverse=True) # 1,4,5,9 to 0,1,2,3\n",
    "    dataset_023678_train = tf.contrib.data.Dataset.from_tensor_slices((X_023678_train,y_023678_train))\n",
    "    #print(dataset_023678_train)\n",
    "\n",
    "    X_023678_test = np.compress(np.array(mask_023678_test), mnist.test.images, axis=0)\n",
    "    _, y_023678_test = np.unique(mnist.test.labels[mask_023678_test], return_inverse=True)\n",
    "\n",
    "prepare_data()\n",
    "\n",
    "# for example\n",
    "plot_image(X_1459_test[2].reshape(28,28),title=y_1459_test[2])\n",
    "plot_image(X_023678_test[2].reshape(28,28),title=y_023678_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "n_outputs = 4\n",
    "\n",
    "reset_graph()\n",
    "prepare_data()\n",
    "\n",
    "# The random seed that defines initialization.\n",
    "#SEED = 42\n",
    "\n",
    "conv1_weights = tf.Variable(\n",
    "  tf.truncated_normal([5, 5, channels, 32],  # 5x5 filter, depth 32.\n",
    "                      stddev=0.1,\n",
    "                      seed=42))\n",
    "\n",
    "conv1_biases = tf.Variable(tf.zeros([32])) # Bias variable\n",
    "\n",
    "conv2_weights = tf.Variable(\n",
    "  tf.truncated_normal([5, 5, 32, 64],\n",
    "                      stddev=0.1,\n",
    "                      seed=42))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64])) # Bias vairable for the next layer\n",
    "\n",
    "#inputs layer\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels]) # Reshaped image\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"conv\"):\n",
    "    conv1 = tf.layers.conv2d(X_reshaped, kernel_size=[5, 5],filters=32, strides=1,activation=tf.nn.relu,padding='SAME')\n",
    "    # Bias and rectified linear non-linearity.\n",
    "    #relu = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    conv2 = tf.layers.conv2d(pool1, kernel_size=[5, 5],filters=64, strides=1,activation=tf.nn.relu,padding='SAME')\n",
    "    #relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    pool3_flat = tf.reshape(pool3, [-1, 7 * 7 * 64])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, 16, name=\"fc1\", activation=tf.nn.relu)\n",
    "\n",
    "with tf.name_scope(\"fc2\"):\n",
    "    fc2 = tf.layers.dense(fc1, 10, name = \"fc2\", activation = tf.nn.relu)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc2,4, name = \"logits\", activation = tf.nn.relu)\n",
    "    Y_proba = tf.nn.softmax(logits, name = \"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 1459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 10\n",
    "\n",
    "print(\"Training...\")\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    batched_dataset = dataset_1459_train.batch(batch_size)\n",
    "\n",
    "    iterator = batched_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(iterator.initializer)\n",
    "        while True:\n",
    "            try:\n",
    "                X_batch, y_batch = sess.run(next_batch)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                # finished running through dataset\n",
    "                break\n",
    "\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_1459_train, y: y_1459_train})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_1459_test, y: y_1459_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "        \n",
    "    print(\"Finished training\")\n",
    "\n",
    "    print(\"Saving...\")\n",
    "    save_path = saver.save(sess, \"./my_model_1459.ckpt\")\n",
    "        \n",
    "    # for example\n",
    "    inferred = sess.run(Y_proba, feed_dict={X: [X_1459_test[0]]})\n",
    "    plot_image(X_1459_test[0].reshape(28,28), \"Predicted %d, truth %d\"%(np.argmax(inferred), y_1459_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the graph for 023678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "prepare_data()\n",
    "\n",
    "# restore the graph of 1459\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_model_1459.ckpt.meta\")\n",
    "\n",
    "# reuse the inputs (X,y)\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"inputs/X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"inputs/y:0\")\n",
    "# reuse the FC1 layer\n",
    "fc1 = tf.get_default_graph().get_tensor_by_name(\"fc1/fc1/Relu:0\")\n",
    "# reuse the FC2 layer\n",
    "fc2_reuse = tf.get_default_graph().get_tensor_by_name(\"fc2/fc2/Relu:0\")\n",
    "\n",
    "# continue the 023678 graph from FC2...\n",
    "with tf.name_scope(\"fc2_023678\"):\n",
    "    fc2 = tf.layers.dense(fc1,10,name=\"fc2_023678\", activation = tf.nn.relu)\n",
    "\n",
    "with tf.name_scope(\"softmax_023678\"):\n",
    "    logits = tf.layers.dense(fc2, 4, name=\"output_023678\",activation = tf.nn.relu)\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba_023678\")\n",
    "\n",
    "with tf.name_scope(\"train_023678\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer(name=\"adam_023678\")\n",
    "## try to freeze everything but fc2, softmax\n",
    "#     train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"fc2_023678|softmax_023678\")\n",
    "#     training_op = optimizer.minimize(loss, var_list=train_vars)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval_023678\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_023678\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train transferred 023678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "batch_size = 10\n",
    "\n",
    "print(\"Training 023678...\")\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    batched_dataset = dataset_023678_train.batch(batch_size)\n",
    "\n",
    "    iterator = batched_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "    \n",
    "    saver.restore(sess, \"./my_model_1459.ckpt\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(iterator.initializer)\n",
    "        while True:\n",
    "            try:\n",
    "                X_batch, y_batch = sess.run(next_batch)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                # finished running through dataset\n",
    "                break\n",
    "\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_023678_train, y: y_023678_train})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_023678_test, y: y_023678_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "        \n",
    "    print(\"Finished training\")\n",
    "\n",
    "    # for example\n",
    "    inferred = sess.run(Y_proba, feed_dict={X: [X_023678_test[0]]})\n",
    "    plot_image(X_023678_test[0].reshape(28,28), \"Predicted %d, truth %d\"%(np.argmax(inferred), y_023678_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Feature Maps\n",
    "The following code is useful to look into the activations of convolutional and pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    saver.restore(sess, \"./my_model_1459.ckpt\")\n",
    "    getActivations(tf.get_default_graph().get_tensor_by_name(\"correct:0\"), X_1459_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the convolution kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_1459.ckpt\")\n",
    "    \n",
    "    #plotConvLayerWeights(,sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Execution Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "# restore the graph of 1459\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_model_1459.ckpt.meta\")\n",
    "\n",
    "show_graph(tf.get_default_graph())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
